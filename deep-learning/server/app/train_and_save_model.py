"""
Script d'entraÃ®nement et sauvegarde du modÃ¨le CamemBERT
Classification des thÃ©matiques de budgets participatifs

Ce script:
- Charge et prÃ©pare les donnÃ©es
- EntraÃ®ne un modÃ¨le CamemBERT en mode Fine-Tuning
- Sauvegarde le modÃ¨le et les fichiers nÃ©cessaires pour l'API
"""

import os
import json
import numpy as np
import pandas as pd
import re

# Configuration pour Keras 3 avec Transformers
os.environ['TF_USE_LEGACY_KERAS'] = '1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import warnings
warnings.filterwarnings('ignore')

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

from transformers import CamembertTokenizer, TFCamembertModel

# Configuration
SEED = 42
LEARNING_RATE = 5e-5  # Meilleur learning rate identifiÃ©
MAX_LENGTH = 128
BATCH_SIZE = 32
EPOCHS = 10

# ReproductibilitÃ©
np.random.seed(SEED)
tf.random.set_seed(SEED)
keras.utils.set_random_seed(SEED)

print("=" * 80)
print("ðŸš€ ENTRAÃŽNEMENT DU MODÃˆLE CAMEMBERT")
print("=" * 80)

# =============================================================================
# 1. CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES
# =============================================================================

print("\nðŸ“¥ Chargement du dataset...")
df = pd.read_csv('data/dataset-for-training-completed.csv')
print(f"âœ… Dataset chargÃ© : {len(df)} lignes")

# Nettoyage
print("ðŸ§¹ Nettoyage des donnÃ©es...")
df = df.dropna()
df['ThÃ©matique'] = df['ThÃ©matique'].str.strip()
df = df[df['ThÃ©matique'].str.len() > 0]
df = df[~df['ThÃ©matique'].str.match(r'^[\W_]+$')]
print(f"âœ… AprÃ¨s nettoyage : {len(df)} lignes")

# PrÃ©traitement du texte
def preprocess_text(text):
    """Normalisation du texte franÃ§ais"""
    text = text.lower()
    text = re.sub(r"[^a-zÃ Ã¢Ã¤Ã¦Ã§Ã©Ã¨ÃªÃ«Ã¯Ã®Ã´Ã¹Ã»Ã¼Ã¿Å“'\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

print("ðŸ”„ Nettoyage des titres...")
df['Titres opÃ©ration et projet laurÃ©at'] = df['Titres opÃ©ration et projet laurÃ©at'].apply(preprocess_text)
print("âœ… Titres nettoyÃ©s")

# Encodage des labels
print("ðŸ”¢ Encodage des thÃ©matiques...")
label_encoder = LabelEncoder()
label_encoder.fit(df['ThÃ©matique'])
y_all_encoded = label_encoder.transform(df['ThÃ©matique'])
num_classes = len(label_encoder.classes_)
print(f"âœ… {num_classes} thÃ©matiques encodÃ©es")

# SÃ©paration train/val/test
print("ðŸ“Š SÃ©paration des donnÃ©es...")
X_all = df['Titres opÃ©ration et projet laurÃ©at'].values
y_all = y_all_encoded

X_train_all_text, X_test_text, y_train_all, y_test = train_test_split(
    X_all, y_all, test_size=0.3, random_state=SEED, stratify=y_all
)

X_train_text, X_val_text, y_train, y_val = train_test_split(
    X_train_all_text, y_train_all, test_size=0.2, random_state=SEED, stratify=y_train_all
)

print(f"âœ… Train: {len(X_train_text)} | Val: {len(X_val_text)} | Test: {len(X_test_text)}")

# =============================================================================
# 2. TOKENIZATION AVEC CAMEMBERT
# =============================================================================

print("\nðŸ“¥ Chargement du tokenizer CamemBERT...")
tokenizer_camembert = CamembertTokenizer.from_pretrained("camembert-base")
print("âœ… Tokenizer chargÃ©")

def tokenize_data(texts, max_length=MAX_LENGTH):
    """Tokenize les textes avec CamemBERT"""
    return tokenizer_camembert(
        texts.tolist(),
        padding='max_length',
        truncation=True,
        max_length=max_length,
        return_tensors='tf'
    )

print("ðŸ”„ Tokenization des donnÃ©es...")
X_train_camembert = tokenize_data(X_train_text)
X_val_camembert = tokenize_data(X_val_text)
X_test_camembert = tokenize_data(X_test_text)
print("âœ… Tokenization terminÃ©e")

# =============================================================================
# 3. CRÃ‰ATION DU MODÃˆLE
# =============================================================================

print("\nðŸ”¨ CrÃ©ation du modÃ¨le CamemBERT Fine-Tuned...")

def creer_modele_camembert_finetuned():
    """CrÃ©e un modÃ¨le CamemBERT avec fine-tuning complet"""
    
    # Charger le backbone CamemBERT
    try:
        camembert_backbone = TFCamembertModel.from_pretrained(
            "camembert-base",
            from_pt=True
        )
        camembert_backbone.trainable = True  # Fine-tuning
    except Exception:
        camembert_backbone = TFCamembertModel.from_pretrained(
            "almanach/camembert-base",
            from_pt=True
        )
        camembert_backbone.trainable = True
    
    # Architecture
    input_ids = layers.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name="input_ids")
    attention_mask = layers.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name="attention_mask")
    
    camembert_output = camembert_backbone(input_ids, attention_mask=attention_mask)
    cls_token = camembert_output.last_hidden_state[:, 0, :]
    
    x = layers.Dropout(0.3)(cls_token)
    x = layers.Dense(64, activation='relu')(x)
    x = layers.Dropout(0.3)(x)
    output = layers.Dense(num_classes, activation='softmax')(x)
    
    model = keras.Model(inputs=[input_ids, attention_mask], outputs=output)
    
    return model

model = creer_modele_camembert_finetuned()

# Compilation
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print(f"âœ… ModÃ¨le crÃ©Ã© et compilÃ© (Learning Rate: {LEARNING_RATE})")
total_params = sum([tf.size(w).numpy() for w in model.trainable_weights])
print(f"ðŸ“Š ParamÃ¨tres entraÃ®nables: {total_params:,}")

# =============================================================================
# 4. ENTRAÃŽNEMENT
# =============================================================================

print("\nðŸš€ DÃ©but de l'entraÃ®nement...")
print("=" * 80)

# Callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True, verbose=0)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-7, verbose=0)

# EntraÃ®nement
history = model.fit(
    [X_train_camembert['input_ids'], X_train_camembert['attention_mask']],
    y_train,
    validation_data=(
        [X_val_camembert['input_ids'], X_val_camembert['attention_mask']],
        y_val
    ),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

print("=" * 80)
print("âœ… EntraÃ®nement terminÃ©")
print(f"ðŸ“Š Meilleure val_accuracy: {max(history.history['val_accuracy']):.4f}")
print(f"ðŸ“Š Meilleure val_loss: {min(history.history['val_loss']):.4f}")

# =============================================================================
# 5. Ã‰VALUATION SUR LE TEST SET
# =============================================================================

print("\nðŸ“Š Ã‰valuation sur le test set...")
test_loss, test_acc = model.evaluate(
    [X_test_camembert['input_ids'], X_test_camembert['attention_mask']],
    y_test,
    verbose=0
)
print(f"âœ… Test Loss: {test_loss:.4f}")
print(f"âœ… Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)")

# =============================================================================
# 6. SAUVEGARDE DU MODÃˆLE ET DES FICHIERS
# =============================================================================

print("\nðŸ’¾ Sauvegarde des fichiers...")
print("=" * 80)

# CrÃ©er le dossier de sauvegarde
save_dir = '../model/camembert/'
os.makedirs(save_dir, exist_ok=True)

# 1. Sauvegarder le modÃ¨le en .h5 (utilisÃ© par l'API FastAPI)
model_h5_path = f'{save_dir}camembert-budgets-participatif.h5'
model.save(model_h5_path)
model_size = os.path.getsize(model_h5_path) / (1024**2)
print(f"âœ… ModÃ¨le sauvegardÃ© (.h5): {model_h5_path}")
print(f"   Taille: {model_size:.1f} MB")

# 2. Sauvegarder le label mapping en JSON
label_mapping_json_path = f'{save_dir}camembert_label_mapping.json'
mapping_dict = {int(i): str(label) for i, label in enumerate(label_encoder.classes_)}
reverse_mapping = {str(label): int(i) for i, label in enumerate(label_encoder.classes_)}

with open(label_mapping_json_path, 'w', encoding='utf-8') as f:
    json.dump({
        'num_to_label': mapping_dict,
        'label_to_num': reverse_mapping,
        'num_classes': num_classes,
        'learning_rate': LEARNING_RATE,
        'test_accuracy': float(test_acc),
        'test_loss': float(test_loss)
    }, f, ensure_ascii=False, indent=2)

print(f"âœ… Label mapping sauvegardÃ©: {label_mapping_json_path}")
print("\n" + "=" * 80)
print("ðŸŽ‰ ENTRAÃŽNEMENT ET SAUVEGARDE TERMINÃ‰S AVEC SUCCÃˆS !")
print("=" * 80)
print("\nðŸ“‹ Fichiers crÃ©Ã©s:")
print(f"   1. {model_h5_path}")
print(f"   2. {label_mapping_json_path}")

print("\nðŸ’¡ Le modÃ¨le est prÃªt Ã  Ãªtre utilisÃ© par l'API FastAPI")
print(f"ðŸ“Š Performance finale: {test_acc*100:.2f}% d'accuracy sur le test set")
